شرح الشريحة التاسعة (مثال: مصدر ثنائي ودالة شانون)النص:$\rhd$ Average Information Contentالشرح:ننتقل الآن إلى تطبيق معادلة الإنتروبيا على أبسط أنواع مصادر المعلومات، وهو المصدر الثنائي.النص:Example: binary source with $X = \{x_1, x_2\}$الشرح:المثال هو مصدر ثنائي (Binary Source)، أي أنه يولد رمزين فقط، هما $x_1$ و $x_2$. (مثل بت 0 وبت 1).النص:Probabilities: $p(x_1) = p$, $p(x_2) = 1 - p$الشرح:نفرض أن احتمال ظهور الرمز الأول $x_1$ هو $p$. وبما أن المصدر يولد رمزَيْن فقط، فإن احتمال ظهور الرمز الثاني $x_2$ يجب أن يكون المتبقي، أي $(1 - p)$.النص:Entropy: $H(X) = -p \text{ ld}(p) - (1-p) \text{ ld}(1-p)$الشرح:بتطبيق الصيغة العامة للإنتروبيا $\left(H(X) = \sum p(x_i) \cdot \text{ld}\left(\frac{1}{p(x_i)}\right)\right)$ على المصدر الثنائي، نحصل على المعادلة:$$H(X) = -p \text{ ld}(p) - (1-p) \text{ ld}(1-p)$$النص:Shannon function: $H(X) = S(p)$الشرح:تُعرف هذه الدالة تحديداً باسم دالة شانون الثنائية، ويُرمز لها بالرمز $S(p)$، وهي تصف الإنتروبيا كدالة لاحتمالية ظهور الرمز $p$.النص:الشرح:يوضح الرسم البياني شكل دالة شانون $S(p)$:الحد الأقصى (Maximum): تصل الإنتروبيا إلى أقصى قيمة لها (1 بت) عندما تكون الاحتمالية $p$ تساوي 0.5. وهذا يعني أن أقصى عدم يقين وأعلى محتوى معلومات يحدث عندما تكون الرموز متساوية الاحتمال.الحد الأدنى (Minimum): تكون الإنتروبيا صفر عندما تكون $p=0$ أو $p=1$. هذا يعني أننا نحصل على صفر معلومات عندما نعرف مسبقاً نتيجة الرمز (يقين تام).