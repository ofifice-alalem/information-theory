شرح الشريحة العاشرة (الحد الأقصى للإنتروبيا والتكرار)النص:$\rhd$ Average Information Contentالشرح:نستنتج من الأمثلة والتعريفات السابقة العلاقة الأساسية بين الإنتروبيا الفعلية لمصدر ما $H(X)$ وقيمة الإنتروبيا المثالية $H_0$.النص:The entropy becomes maximum for equiprobable symbols, however, the entropy is less than or equal the number of binary decisions $H_0$الشرح:تذكروا أننا رأينا في دالة شانون أن الإنتروبيا تكون في أقصى قيمة لها (Maximum) عندما تكون الرموز متساوية الاحتمال (Equiprobable). وفي هذه الحالة فقط، تتساوى قيمة الإنتروبيا $H(X)$ مع القيمة النظرية $H_0$. ولكن في أي حالة أخرى تكون أقل من أو تساوي $H_0$.النص:$$H(X) \leq H_0 = \text{ld} N$$الشرح:توضح هذه المتراجحة أن الحد الأقصى لمتوسط المعلومات (الإنتروبيا) هو القيمة التي حُسبت سابقاً على افتراض التوزيع المتساوي ($H_0$). أي أن: لا يمكن لأي مصدر معلومات أن ينتج معلومات أكثر من الحد الأقصى النظري $\boldsymbol{\text{ld} N}$.النص:The redundancy of a source can be calculated:الشرح:بما أن الإنتروبيا الفعلية $H(X)$ غالباً ما تكون أقل من الحد الأقصى $H_0$، فإن الفرق بينهما يمثل المعلومات الزائدة أو المُكررة (Redundancy) الموجودة في المصدر.النص:$$R_S = H_0 - H(X)$$الشرح:يمكن حساب التكرار (Redundancy) للمصدر $R_S$ بطرح الإنتروبيا الفعلية $H(X)$ من الإنتروبيا القصوى $H_0$. هذا التكرار هو جزء من المعلومات الذي يمكن إزالته عبر ترميز المصدر (Source Coding) (مثل الضغط) لزيادة كفاءة الإرسال.